\chapter {Miner\'ia y an\'alisis computacional de sentimientos}\label{Mineria}

\paragraph{Las opiniones son fuertemente influyentes sobre el comportamiento de las personas en la mayor\'ia de sus actividades. Nuestras creencias, decisiones y percepci\'on de la realidad est\'an condicionadas por la visi\'on que perciben las dem\'as personas en nuestro entorno. El \'area de estudio denominada ``an\'alisis de sentimientos'', conocida tambi\'en como ``miner\'ia de opiniones'' se ocupa de conceptos tales como opini\'on, sentimiento, actitud y evaluaci\'on (Liu, 2012).}
\paragraph{En este cap\'itulo definimos el an\'alisis computacional como un Proceso de Descubrimiento de Conocimiento (KDD por sus siglas en ingl\'es, \textit{Knowledge Discovery in Databases}) y como un \'area de estudio del Procesamiento de Lenguaje Natural (PLN). Luego, se presentan las estrategias m\'as utilizadas en el campo, adem\'as de una breve descripci\'on de los trabajos similares m\'as recientes que utilizan dichas estrategias para la clasificaci\'on de sentimientos.}

\section{Proceso de Descubrimiento de Conocimiento}
\paragraph{Los datos son un conjunto discreto de hechos sobre ciertos eventos; los datos en s\'i no describen las condiciones de un evento, o posibles interpretaciones sobre el mismo, solamente sumarizan caracter\'isticas de dichos eventos. Su importancia radica en que sirven de materia prima en el proceso de generaci\'on de informaci\'on.}
\paragraph{Los datos se convierten en informaci\'on cuando el receptor de dichos datos da un sentido o interpretaci\'on a los mismos, entonces podemos definir a la informaci\'on como un conjunto de datos con sentido, relevancia y prop\'osito para el receptor de los datos.}
\paragraph{A partir de informaciones obtenidas, podemos definir KDD como el proceso no trivial de identificaci\'on de patrones v\'alidos, novedosos, potencialmente \'utiles y comprensibles en un conjunto de datos (Fayyad y otros, 1996). Este proceso puede ser aplicado al an\'alisis de sentimientos, puesto que buscamos identificar patrones en un lenguaje de entrada, que describan significativamente las opiniones del tal manera que podamos clasificarlas, por ejemplo, como ``positivas'' o ``negativas'' y presentarlas como informaci\'on generada.}

\begin{figure}[h]
\centering
\includegraphics[width=1 \textwidth]{etapaskdd.png}
\caption{Etapas en el proceso de KDD}
\label{etapaskdd}
\end{figure}

\paragraph{En el proceso de KDD podemos distinguir una serie de etapas, como se puede observar en la Figura \ref{etapaskdd}, las cuales describimos a continuaci\'on: }

\begin{itemize}

\item \textbf{Selecci\'on:} En esta etapa, el objetivo es escoger una fuente o conjunto de fuentes de datos como entrada. La selecci\'on de las fuentes se da a partir del an\'alisis previo del problema, de tal manera que los datos escogidos sean representativos del problema y resulten \'utiles para descubrir conocimiento. Adem\'as, se pueden generar nuevos repositorios de datos a partir del conjunto de datos seleccionado. La recolecci\'on, descripci\'on y exploraci\'on de datos son tareas comunes en esta fase del proceso.
\item \textbf{Preprocesamiento:} Esta etapa involucra operaciones de limpieza y preprocesamiento de los datos, as\'i como tambi\'en de integraci\'on de diferentes fuentes de datos. Algunas tareas comunes que efect\'uan en esta etapa son la selecci\'on de columnas para el an\'alisis de datos, la limpieza de los datos con ``ruido'', eliminaci\'on de registros repetidos y la definici\'on de acciones sobre los campos con registros nulos.
\item \textbf{Transformaci\'on:} La transformaci\'on de datos se efect\'ua con el objetivo de conseguir una caracterizaci\'on o representaci\'on de los datos, acorde a los objetivos planteados y, si es posible, reducir la cantidad de variables o atributos considerados, buscando un buen desempe\~no en las siguientes fases del proceso. Algunas tareas comunes en esta etapa son la discretizaci\'on de valores, agrupaciones por tipos y la reducci\'on de variables.
\item \textbf{Extracci\'on de Patrones:} En esta etapa se llevan a cabo trabajos de decisi\'on sobre los modelos y par\'ametros adecuados para obtener resultados coherentes y esperados sobre los datos, mapeando dichos modelos con las tareas adecuadas de miner\'ia para cada criterio u objetivo definido en el modelado. Las tareas comunes en esta fase del proceso son la clasificaci\'on, agrupaci\'on, asociaci\'on, visualizaci\'on y sumarizaci\'on de elementos, adem\'as de la detecci\'on de desv\'ios, estimaci\'on de valores, an\'alisis de relacionamiento, entre otras.
\item \textbf{Interpretaci\'on y Evaluaci\'on:} De acuerdo a los datos obtenidos, este paso primariamente implica una retroalimentaci\'on de las etapas previas con el fin de corregir errores o mejorar ciertos procedimientos. Adem\'as se realiza una visualizaci\'on sobre los patrones y modelos obtenidos de manera a comprender dichos resultados y extraer conocimientos. Durante las acciones de comprensi\'on y descubrimiento de conocimiento, se pueden presentar casos en los cuales los resultados generen conflictos con algunos conocimientos previos, por tanto la resoluci\'on de dichos inconvenientes puede implicar la modificaci\'on o actualizaci\'on de ciertos par\'ametros aplicados en pasos anteriores.

\end{itemize}


\section{Preprocesamiento de entradas}
\paragraph{Este paso se efect\'ua previamente al de la estrategia de categorizaci\'on seleccionada, con el objetivo de limitar y refinar los espacios de b\'usqueda. En esta etapa del proceso se define cu\'ales entradas son relevantes y la disposici\'on m\'as eficiente en la que pueden ser introducidas al proceso de clasificaci\'on. Algunas t\'ecnicas de preprocesamiento son las siguientes:}

\begin{itemize}

\item \textbf{Utilizaci\'on de n-gramas:} Los datos pueden ser introducidos en forma de n-gramas. Un n-grama consiste en una subsecuencia de n-elementos de una secuencia dada. En el estudio del lenguaje natural, se pueden introducir elementos de distinta granularidad, como letras, s\'ilabas o palabras. Sin embargo, en el an\'alisis de sentimientos, generalmente se utilizan las palabras. El caso base para la disposici\'on de los datos es la utilizaci\'on de las palabras como unigramas (subsecuencias de un elemento). Otra variante muy utilizada y que es objeto de varios experimentos con resultados positivos, es la introducci\'on de bigramas (subsecuencias de dos palabras) con el objetivo de aumentar la precisi\'on en la determinaci\'on de la polaridad de los textos, partiendo de la idea que con ellas se puede lograr una mejor evaluaci\'on de intensificadores, negadores y otros fen\'omenos gramaticales; por ejemplo, ``muy bueno'', ``no apto'' son bigramas significativos.

\item \textbf{Eliminaci\'on de stopwords:} Las \textit{stopwords} son un conjunto de palabras de uso muy frecuente y que son omitidas en el proceso de b\'usqueda, pues no representan entradas significativas (ru\'ido) para el an\'alisis pertinente; en este caso, cargas de polaridad. Varias de ellas son propias de la gram\'atica, como art\'iculos, nombres, preposiciones y otras categor\'ias l\'exicas; algunos ejemplos son: ``ac\'a'', ``ah\'i'', ``alg\'un'', ``del'', ``en'', entre otras. Otras palabras no significativas para el an\'alisis de sentimientos pueden ser aquellas relativas al dominio, pues son utilizadas de manera muy frecuente y tampoco implican orientaci\'on a alguna polaridad determinada; por ejemplo, en una cr\'itica de cine, estas palabras podr\'ian ser ``actor'', ``actuaci\'on'', ``sonido'', entre otras.

\item \textbf{Stemming:} El m\'etodo de \textit{stemming} consiste en obtener la ra\'iz sem\'antica de cada palabra con el objetivo de asociar las palabras con dicha ra\'iz. Con esto se logra reducir las formas derivadas de las palabras a su forma base. Por ejemplo, la ra\'iz del verbo ``aprender'' es ``aprend'', con lo que se logra asociar las conjugaciones de dicho verbo como ``aprende'', ``aprendo'', ``aprendiendo'', etc.

\item \textbf{Lematizaci\'on} La lematizaci\'on es similar al m\'etodo de \textit{stemming}, a diferencia de que \'este toma como ra\'iz de las palabras un subconjunto de letras de la misma; mientras que en el proceso de lematizaci\'on, se busca hallar el lema de una palabra, es decir su forma gen\'erica o como la encontrar\'iamos en un diccionario. Por ejemplo, mediante lematizaci\'on se puede lograr reducir la forma ``hice'' a su lema ``hacer'', mientras que esto no ser\'ia posible mediante \textit{stemming}.

\item \textbf{An\'alisis de estructuras gramaticales:} Llamada tambi\'en POS (por sus siglas en ingl\'es, \textit{``part-of-speech''}). Consiste en el etiquetado de las palabras seg\'un su categor\'ia gramatical, debido a que algunas de ellas son indicadoras m\'as relevantes de opini\'on. Ciertas categor\'ias como por ejemplo, los adjetivos o los adverbios, son m\'as descriptivas para detectar polaridad en una oraci\'on que los sustantivos, los verbos o los art\'iculos. Algunas aplicaciones de esta t\'ecnica son la asignaci\'on de pesos a las palabras por categor\'ia o bien la utilizaci\'on de las etiquetas mismas como atributos para un conjunto de entrenamiento.

%\paragraph{POS Tagging, an\'alisis sint\'actico de dependencias, etc}

\end{itemize}



\section{Estrategias basadas en l\'exicos}
\paragraph{En cualquier lenguaje, existen palabras com\'unmente utilizadas para expresar opini\'on o ``sentimiento'' con una orientaci\'on determinada respecto a una entidad en particular. Dicha orientaci\'on puede ser positiva o negativa; por ejemplo: ``bueno'', ``genial'' y ``espectacular'' son entradas positivas; mientras que ``malo'', ``p\'esimo'' y ``horrible'' son entradas negativas. Estas palabras, denominadas \textit{sentiment words} (SW, por sus siglas en ingl\'es) en conjunto conforman un l\'exico de sentimientos u opiniones. Para conformar dicho l\'exico, pueden ser tomados como fuentes distintos textos escritos, cuyos contenidos traten de evaluar o expresar opini\'on sobre alguna entidad, como por ejemplo cr\'iticas, libros, recetas, p\'aginas Web, entre otros.} 
\paragraph{Las SW podemos clasificar en palabras descriptivas y comparativas. Las palabras descriptivas expresan calificaci\'on sobre una entidad, tales como las citadas en el p\'arrafo anterior; mientras que las palabras comparativas establecen confrontaci\'on entre dos entidades, generando opiniones superlativas. Por ejemplo, en la oraci\'on ``El producto A es mejor que el producto B'' no se establece calificaci\'on positiva ni negativa para alguno de los productos, sino que solamente en comparaci\'on al producto B, el A es mejor. Esto no implica que ``mejor'' sea exclusivamente una SW comparativa para cualquier oraci\'on, sino que cumple tal funci\'on en el contexto dado.}
\paragraph{En algunos l\'exicos, la orientaci\'on sem\'antica de las palabras es cuantificada generalmente por valores num\'ericos, que luego son introducidos en una funci\'on de puntuaci\'on, para determinar la polaridad de una opini\'on acerca de una entidad determinada. Dicha funci\'on var\'ia seg\'un el an\'alisis de distintos autores; as\'i como los criterios de cuantificaci\'on de las orientaciones sem\'anticas. En algunos trabajos, se limitan a asignar signos positivos y negativos (+1 y -1) a las palabras (Ding y otros, 2008); mientras que en otros, se emplea un intervalo m\'as amplio para obtener un mejor balance de la suma final de polaridades, como (Taboada y otros, 2011) que utilizan un intervalo de puntuaci\'on de -5 a +5. Estas puntuaciones, as\'i como las funciones definidas para el c\'alculo de polaridad, pueden influir en la precisi\'on de resultados logrados.}
\paragraph{En (Liu, 2012) se identifican tres tipos de estrategia para compilar SW que conformen un l\'exico: la generaci\'on manual, la generaci\'on basada en un diccionario y la generaci\'on basada en un corpus.}

\subsection{L\'exico generado manualmente}
\paragraph{Seguir esta estrategia implica un costo muy alto de trabajo y de tiempo, por tanto generalmente no es utilizada de manera exclusiva. Tiene su utilidad en combinaci\'on con estrategias automatizadas mediante tareas tales como una verificaci\'on final de palabras, puesto que con los m\'etodos automatizados se pueden generar errores.}

\subsection{L\'exico basado en un diccionario}
\paragraph{La construcci\'on de un diccionario implica un listado de sin\'onimos y ant\'onimos para cada palabra. Un m\'etodo sencillo de generaci\'on es utilizar como semillas algunas SW, a partir de las cuales se pueden encontrar las dem\'as palabras del diccionario a partir de los sin\'onimos y ant\'onimos de las semillas. A medida que dichos sin\'onimos son agregados como nuevas palabras semilla, el diccionario va creciendo sucesivamente. Algunos trabajos que se ocupan de la generaci\'on de un diccionario son (Hu y Liu, 2004) y (Kim y Hovy, 2004).}
\paragraph{La ventaja de utilizar un diccionario es que se puede encontrar f\'acil y r\'apidamente un gran n\'umero de SW con sus orientaciones sem\'anticas. A pesar de que la lista resultante puede incluir varios errores, es posible efectuar una verificaci\'on manual de limpieza para refinar el diccionario. Por otro lado, la principal desventaja es que la lista de palabras generadas en un diccionario son de prop\'osito muy general (no orientadas al dominio de aplicaci\'on) y dependientes del contexto. Esta dificultad puede tratada mediante la generaci\'on de un corpus.}

\subsection{L\'exico basado en un corpus}
\paragraph{Esta estrategia fue mayormente aplicada frente a dos escenarios:}
\begin{enumerate}
\item Dado un listado base de SW conocidas, de prop\'osito general, se descubren nuevas SW con sus orientaciones para un determinado dominio.
\item Adaptar un l\'exico de prop\'osito general a uno nuevo utilizando un corpus para aplicaciones de an\'alisis de sentimientos en el dominio.
\end{enumerate}
\paragraph{Construir un l\'exico de sentimientos para un dominio espec\'ifico puede no ser suficiente puesto que en el mismo dominio, una misma palabra puede ser positiva en un contexto, pero negativo en otro. Esta estrategia tambi\'en puede ser utilizada para construir un l\'exico de prop\'osito general en el caso que se encuentre disponible un corpus muy grande y diverso, pero para tal prop\'osito es m\'as efectiva la elaboraci\'on de un diccionario, puesto que el mismo ya est\'a compuesto por todas las palabras. Algunos trabajos que tratan la generaci\'on de un corpus son (Turney, 2002) y (Ding y otros, 2008). }

\subsection{Procesamiento de Lenguaje Natural}
\paragraph{Para extraer las opiniones o sentimientos (informaci\'on) a partir de un texto, el an\'alisis del mismo debe ser tratado como un problema de PLN. Como tal, debe considerar todos los aspectos de ella, como por ejemplo la desambiguaci\'on de palabras, las negaciones, intensificaciones, decrementaciones, entre otros.}
\paragraph{El problema espec\'ifico de extracci\'on de opiniones, es un problema de PLN restringido puesto que no es necesario entender completamente la sem\'antica de cada oraci\'on o documento, mas debe interpretar \'unicamente ciertos aspectos de ellos, como los sentimientos positivos o negativos y las entidades o t\'opicos a los que se refieren. De todas maneras, existen tambi\'en otros problemas a\'un no resueltos de PLN que agregan ciertas dificultades al proceso de an\'alisis. A continuaci\'on, describimos algunos t\'opicos que representan tanto aspectos comunes como dificultades que son tratadas en los problemas de PLN.}

\begin{itemize}

\item \textbf{Desambiguaci\'on de palabras:} Es un aspecto a llevar en cuenta, puesto que en el lenguaje de entrada pueden existir varias palabras que presentan polisemia, es decir cuando una  misma palabra representa diversos significados o acepciones. Esto conduce a que parte del problema considerado es identificar 	el sentido de la palabra dentro de una determinada oraci\'on o documento. Por ejemplo, la palabra ``vaya'' podr\'ia representar un verbo conjugado en presente subjuntivo, en modo imperativo, o incluso una interjecci\'on que denota admiraci\'on o asombro. La diferenciaci\'on de dichos significados es una capacidad humana sencilla, pero debe poder reproducirse adem\'as en los algoritmos de interpretaci\'on que sean desarrollados.
\item \textbf{Negaci\'on:} Es un elemento ling\"u\'istico que, como lo dice su nombre, se utiliza para negar una oraci\'on entera o alguna idea contenida en ella, mediante la utilizaci\'on de adverbios de negaci\'on. Tales adverbios pueden ser utilizados en distintos \'ordenes para referirse a la idea negada, es decir pueden aparecer antes, en medio o despu\'es de ellas. Algunos de estos adverbios de negaci\'on son ``no'', ``nunca'', ``jam\'as'', ``tampoco'', ``nada'' y ``negativamente''.
\item \textbf{Intensificaci\'on y Atenuaci\'on:} Consisten en la utilizaci\'on de ciertos adverbios como recursos ling\"u\'isticos para aumentar o disminuir la intensidad de alguna idea transmitida.  Algunos intensificadores de ejemplo son ``muy'', ``mucho'', ``demasiado'' y ``sobremanera'',  mientras que adverbios como ``poco'', ``menos'', ``solamente'', ``apenas'', ``justo'' son atenuadores.
\item \textbf{Palabras dependientes del contexto:} Son aquellas que no pueden ser definidas como orientadas positivamente o negativamente, sin conocer el dominio del tema que se est\'e abordando. Una palabra puede ser utilizada para referirse positivamente hacia una entidad en un determinado dominio; pero a la vez dicha palabra puede tener una implicancia negativa en un dominio diferente.
Por ejemplo, el adjetivo ``peque\~no'' puede ser visto como positivo refiri\'endose al tama\~no de un tel\'efono celular; o bien como negativo si es referido al tama\~no de una porci\'on de comida servida en un comedor.
\item \textbf{M\'ultiples orientaciones sem\'anticas:} Se presentan cuando se efect\'ua el an\'alisis de un texto que puede estar compuesto por varias oraciones, o bien varias ideas y \'estas pueden tener polaridades diferentes. La entidad a la que se est\'a refiriendo el texto puede ser la misma, pero distintas oraciones pueden referirse a diferentes caracter\'isticas de ella.  Por ejemplo, en la siguiente referencia a una c\'amara fotogr\'afica: ``La calidad de las im\'agenes es muy buena, pero la duraci\'on de la bater\'ia es muy corta.'', la opini\'on acerca de la caracter\'istica de calidad de las im\'agenes es positiva, mientras que la duraci\'on de la bater\'ia es vista negativamente. Ambas aparecen en una misma oraci\'on y adem\'as se refieren a la misma entidad, la c\'amara fotogr\'afica.
\item \textbf{Sarcasmo:} Es una figura que genera dificultades pues cuando se encuentra presente en una oraci\'on, pretende dar a entender lo contrario a lo que las palabras expresan. Es decir, se pueden encontrar varias palabras con orientaci\'on positiva, con la intenci\'on de manifestar negativismo de manera evidente, o viceversa.

\end{itemize}



\section{Estrategias basadas en aprendizaje de m\'aquina}
\paragraph{La estrategia basada en aprendizaje de m\'aquina, tambi\'en referida como estad\'istica o clasificadora de textos, consiste en entrenar un clasificador para categorizar elementos de entrada dentro de una clase perteneciente a un conjunto definido de clases; por ejemplo, de sentimientos positivos, negativos o neutrales. El objetivo es generalizar comportamientos a trav\'es de informaci\'on previamente recolectada, denominada conjunto de entrenamiento, en forma de ejemplos, que luego puedan ser utilizados para evaluar un texto en funci\'on a sus similaridades.}
\paragraph{En t\'erminos generales un conjunto de entrenamiento, llamado en ingl\'es \textit{training set}, es un conjunto de datos que se utiliza para realizar pruebas iniciales sobre un modelo conceptual esperando conseguir una descripci\'on comprensible de dicho modelo y a partir del mismo, la generaci\'on de conocimiento.}
\paragraph{Podemos identificar dos tipos de aprendizaje en esta estrategia: supervisado y no supervisado.}
\paragraph{En un m\'etodo de aprendizaje supervisado, se produce una funci\'on de correspondencia entre las entradas y salidas deseadas del sistema; como por ejemplo clasificar las palabras seg\'un su categor\'ia l\'exica (verbos, sustantivos, adjetivos, etc), categor\'ia funcional (determinantes, cuantificadores, pronombres, etc) o su polaridad (positivas, negativas, neutras, etc), por lo que se necesita una base de conocimiento previamente elaborada, compuesta por ejemplos de etiquetados anteriores.}
\paragraph{Los m\'etodos de aprendizaje no supervisado se llevan a cabo sobre conjuntos de ejemplos conformados \'unicamente por entradas al sistema; sin etiquetado de categor\'ias, a diferencia de los m\'etodos supervisados; por lo que el sistema debe tener capacidad de reconocimiento de patrones para etiquetar nuevas entradas. }
\paragraph{Algunos clasificadores de aprendizaje de m\'aquina son \textit{Na\"ive Bayes} (NB), \textit{Maximum Entropy} (ME) y \textit{Support Vector Machines} (SVM). En las siguientes subseccciones, definimos cada uno de ellos, utilizando el siguiente conjunto de variables:}

\begin{itemize}
\item Un corpus de texto $C$, compuesto por una serie de documentos. La cantidad de documentos es irrelevante y cada uno de ellos es denominado $d$. 
\item Un conjunto de clases $\{c_{1},c_{2},\ldots,c_{n}\}$ definido.
\item Un conjunto de palabras que componen el corpus $C$. Todas las palabras $w$ que componen $C$ representan los atributos del conjunto de entrenamiento.
\end{itemize}
\paragraph{El objetivo es determinar a qu\'e clase $c$ pertenece cada documento $d$.}

\subsection{Na\"ive Bayes}
\paragraph{El algoritmo basado en el teorema de Bayes, aplicado al an\'alisis de textos, consiste en clasificar cada palabra de acuerdo a la probabilidad de que pertenezca a un determinado grupo. Tales agrupaciones pueden estar determinadas por categor\'ias gramaticales o por polaridad. 
La clasificaci\'on por etiquetas gramaticales (\textit{POS tagging}) permite, por ejemplo, establecer la probabilidad de que la palabra siguiente a un sustantivo sea un verbo; con el objetivo de determinar qu\'e influencia tiene una palabra en la polaridad de un texto. En este contexto, un adjetivo es m\'as descriptivo que un sustantivo para la inferencia del sentimiento transmitido en un texto.
La asociaci\'on por polaridad, en cambio relaciona las palabras que componen una oraci\'on con el sentimiento que ellas en conjunto transmiten. Es decir, las palabras utilizadas en una oraci\'on considerada positiva son, con mayor probabilidad, palabras con asociaci\'on positiva para cualquier otra oraci\'on.}
\paragraph{El clasificador \textit{Na\"ive Bayes} deriva del teorema de la probabilidad condicional de dos eventos aleatorios $A$ y $B$ enunciado por Thomas Bayes, donde ``la probabilidad del evento $A$ dado $B$'' est\'a expresado por la siguiente f\'ormula:}
$$P(A \, | \, B) \, = \, {P(A) \, P(B \, | \, A) \over P(B)},$$
\paragraph{Llevando dicho teorema al problema de la clasificaci\'on de textos y utilizando el conjunto de variables antes definido, el primer paso consiste en estimar la probabilidad $P(c)$ de cada clase $c$, dividiendo el n\'umero de palabras presentes en los documentos etiquetados en $c$ entre la cantidad total de palabras en el corpus $C$. Luego, la distribuci\'on de probabilidad $P(w \, | \, c)$ para todas las palabras por cada clase $c$ est\'a dada por la divisi\'on de la cantidad de ocurrencias de $w$ en los documentos etiquetados en $c$ entre la cantidad de palabras en $c$.}
\paragraph{De esta manera, podremos asignar un valor num\'erico a un documento para cada una de las clases, para luego asociarlo a una de ellas. Dicho valor est\'a dado por:}
$$ score(d \, | \, c) \, = \, P(c) \, * \, \prod_{i=1}^n \, P(w_{i} \, | \, c) $$

\paragraph{Luego, la estimaci\'on del modelo ser\'a de aquella clase cuyo valor de $score$ haya resultado mayor que el valor obtenido para las dem\'as clases.}
\paragraph{La dificultad en la aplicaci\'on de este algoritmo es que est\'a cimentado en la hip\'otesis de que las variables evaluadas son independientes entre s\'i (visto en la multiplicaci\'on de los valores de $P(w_{i} \, | \, c)$ en la definici\'on de $score$); y como la gram\'atica es por el contrario, dependiente del contexto, muchas entradas son clasificadas err\'oneamente, originando los fen\'omenos conocidos como ``falsos positivos'' o ``falsos negativos'' si tratamos la polaridad. Sin embargo, los resultados pueden ser a\'un muy positivos con la determinaci\'on de un buen conjunto de entrenamiento.}

\subsection{Maximum Entropy}
\paragraph{El clasificador por entrop\'ia m\'axima trata de generar informaci\'on reduciendo el sesgo al m\'inimo posible. El principio fundamental del algoritmo es que son preferidas las distribuciones uniformes que satisfacen adem\'as todas las restricciones del problema (Nigam y otros, 1999). Dichas restricciones que caracterizan al modelo, son derivadas de los datos etiquetados del conjunto de entrenamiento.}
\paragraph{El algoritmo trata de identificar las caracter\'isticas que definen una clase, definiendo un modelo que englobe las reglas que puedan ser inferidas del conjunto de entrenamiento. Luego, estima un valor esperado para cada una de las clases definidas, de manera a tratarlos como restricciones en el modelo de distribuci\'on (Lee y Renganathan, 2011).}
\paragraph{A diferencia del algoritmo de \textit{Na\"ive Bayes}, no asume la independencia entre variables. En cambio, el modelo busca mediante las restricciones mencionadas, maximizar la adherencia entre atributos en relaci\'on a alguna clase, de tal manera que una nueva entrada ser\'a categorizada dentro una clase cuanto menos caracter\'isticas extr\'insecas a su definici\'on contenga.}
\paragraph{Nigam y otros (1999) definen la probabilidad $P(c \, | \, d)$ de cada clase de la siguiente manera:}
$$ P(c \, | \, d) \, = \, {1 \over Z(d)} \, exp \, 
\left(
\sum_{i} \lambda_{i}F_{i}(d,c)
\right) ,$$
\paragraph{Con la siguiente definici\'on de par\'ametros:}
\begin{itemize}
\item Cada $F_{i}(d,c)$ es un atributo
\item $\lambda_{i}$ es el par\'ametro a ser estimado. Es un indicador de peso; es decir, un valor mayor indica que $F_{i}$ es un indicador m\'as relevante para la clase $c$.
\item $Z(d)$ es una funci\'on de normalizaci\'on para definir una probabilidad apropiada, dada por la siguiente expresi\'on:
$$
Z(d) = \sum_{c} \, exp \, \left( \sum_{i} \lambda_{i}F_{i}(d,c)  \right)
$$
\end{itemize}

\paragraph{La b\'usqueda de $\lambda_{i}$ se realiza por medio de algoritmos de b\'usqueda iterativa definidos seg\'un el modelo, como por ejemplo el m\'etodo de \textit{Hill Climbing} o el de temple simulado.}

\paragraph{Las dificultades que pueden presentarse con el m\'etodo de entrop\'ia m\'axima son la facilidad con la que se presentan casos de \textit{overfitting} (sobreentrenamiento del algoritmo con los datos de entrada dados, que produce p\'erdida de generalizaci\'on para datos nuevos) y el tiempo que pueda emplearse en la determinaci\'on de los pesos puesto que las iteraciones para calcularlos pueden llegar a ser infinitas.}

\subsection{Support Vector Machines}
\paragraph{La t\'ecnica de clasificaci\'on por \textit{Support Vector Machines} efect\'ua la separaci\'on de puntos un espacio $N$-dimensional utilizando un hiperplano $(N-1)$-dimensional, a diferencia de las t\'ecnicas de Bayes y entrop\'ia m\'axima, que utilizan medidas probabil\'isticas para clasificar los puntos. Dado un conjunto de entrenamiento, el clasificador por SVM busca encontrar un hiperplano con el mayor margen posible, de manera que cada punto del conjunto de entrenamiento sea clasificado correctamente y que el hiperplano se encuentre a la m\'axima distancia posible de sus puntos m\'as cercanos. La clasificaci\'on de las instancias de entrenamiento consiste en determinar a qu\'e lado del hiperplano caen ellas. En la pr\'actica, es posible que no se encuentre un hiperplano que separe los grupos perfectamente, por lo que los puntos pueden hallarse dentro del margen o del lado incorrecto del hiperplano.}
\paragraph{Si representamos el hiperplano buscado por el vector $\vec{w}$, la b\'usqueda corresponde a un problema de optimizaci\'on con restricciones, siendo $c_{j} \, \in \, \{1,-1\}$ (positiva y negativa) la clase correcta del texto $d_{j}$, la soluci\'on puede ser escrita como:}
$$ \vec{w} \, := \, \sum_{j} \alpha_{j}c_{j}\vec{d_{j}}, \quad \alpha_{j} \, \geq \, 0, $$
\paragraph{donde las $\alpha_{j}$ son obtenidas por resoluci\'on de un problema de optimizaci\'on. Los vectores $\vec{d_{j}}$, tal que $\alpha_{j}$ es mayor que cero, son llamados vectores de soporte, dado que son los \'unicos que contribuyen al hiperplano $\vec{w}$.}
\paragraph{Ha sido demostrado varias veces que este m\'etodo es altamente efectivo para la categorizaci\'on de textos, obteniendo generalmente mejores resultados que la t\'ecnica de Bayes (Joachims, 1998; Pang y otros, 2002; Kennedy e Inkpen, 2006).}


\section{M\'etricas de evaluaci\'on}
\paragraph{La evaluaci\'on de la clasificaci\'on se efect\'ua primariamente con el objetivo de comparar el desempe\~no de distintos sistemas o m\'etodos entre s\'i. La relevancia y utilidad de los resultados obtenidos prevalecen sobre los tiempos y espacios de respuesta cuando evaluamos una estrategia de an\'alisis de textos. No existe un \'unico criterio que permita determinar que un m\'etodo es mejor que otro; por ello, existen diversas m\'etricas para medir la efectividad de la informaci\'on obtenida del an\'alisis.}
\paragraph{Las m\'etricas que presentamos en esta secci\'on est\'an basadas en la matriz de confusi\'on o de clasificaci\'on. Dicha matriz contrasta la estimaci\'on del modelo clasificador para un elemento dado, con la clase real asociada a dicho elemento.}
\paragraph{Dado un conjunto de datos $E$, donde cada elemento $e$ puede ser representado como un vector $< e_1, e_2, \dots, e_n >$ de $n$ atributos, y un conjunto de clases $C$; cada vector $e \in E$ tiene una clase $c \in C$ asociada. La clasificaci\'on consiste en asignar una clase $c \in C$ para cada elemento $e \in E$, y el objetivo es cuantificar la efectividad de dichas asignaciones. Para dicho efecto, las filas de la matriz de confusi\'on representan las clases reales a la que pertenecen cada uno de los elementos y las columnas representan a la predicci\'on del modelo clasificador, como se observa en el Cuadro \ref{matrizconfusion}.}

\begin{table}[htb] 
\centering

$
\begin{array}{|c|c|c|c|}
      \hline
         				& \mathbf{Clase_1}	& \mathbf{Clase_2}	& \mathbf{Clase_n}	\\
      \hline
      \mathbf{Clase_1}  & V	Clase_1	& F Clase_2	& F Clase_n	\\
      \hline
      \mathbf{Clase_2} 	& F Clase_2 & V Clase_2 & F Clase_n	\\
      \hline
      \mathbf{Clase_n}	& F Clase_n	& F	Clase_2	& V Clase_n	\\
      \hline
\end{array}
$
\caption{Matriz de confusi\'on o de clasificaci\'on}
\label{matrizconfusion}
\end{table}

\paragraph{Referenciando los sub\'indices de filas y columnas como $[i,j]$, una entrada Verdadera representa un acierto, es decir si el clasificador ha determinado que un elemento $e$ pertenece a la $Clase_j$ y dicho elemento efectivamente est\'a asociado a la $Clase_j$; mientras que una entrada Falsa representa un error de clasificaci\'on, es decir que el elemento $e$ no pertenec\'ia efectivamente a la $Clase_j$.} 
\paragraph{Definimos a continuaci\'on algunas m\'etricas de evaluaci\'on, en cuyas definiciones referenciamos a los aciertos y errores con el sub\'indice de la fila $i$ a la que pertenecen en la matriz de confusi\'on, como Verdadero de la $Clase_i$ o Falso de la $Clase_i$ :} 

\subsection{Precisi\'on}
\paragraph{La precisi\'on respecto a la $Clase_i$ indica el n\'umero de predicciones correctas sobre el total de predicciones de dicha clase. Es decir, indica la probabilidad de que un elemento $e$ pertenezca realmente a la $Clase_i$ dado que fue identificado como tal por el clasificador. Est\'a dado por la proporci\'on de verdaderos de la $Clase_i$ en relaci\'on a los totales identificados como de dicha clase: }
\paragraph{
$$ Precisi\acute{o}n = {V Clase_i \over V Clase_i + F Clase_i} $$ }
\subsection{Recall}
\paragraph{El \textit{recall} respecto a la $Clase_i$ indica el n\'umero de predicciones acertadas como $Clase_i$ sobre el total de elementos que realmente pertenecen a dicha clase. Es la probabilidad de que un elemento $e$ que pertenece realmente a la $Clase_i$ sea clasificado como tal. Est\'a dado por la raz\'on entre los verdaderos de la $Clase_i$, sobre los elementos reales de la $Clase_i$, en la matriz de confusi\'on dados por la suma de los verdaderos de la $Clase_i$ m\'as los falsos de las dem\'as clases.}
\paragraph{
$$ Recall = { V Clase_i \over V Clase_i + F Clase_j } \quad donde \quad j \in \lbrace 1,2,\dots,n \rbrace \quad con \quad j \ne i $$ }
\subsection{Medida-F}
\paragraph{Relaciona las medidas de precisi\'on y \textit{recall} mediante una media con el mismo peso para ambas. Es conocida tambi\'en como $F_1$ por la uniformidad de los pesos.}
\paragraph{
$$ Medida-F = {2 \, \times Precisi\acute{o}n \, \times \, Recall \over Precisi\acute{o}n \, + \, Recall}$$ }



\section{Propuestas similares}
\paragraph{En esta secci\'on, describimos algunas propuestas publicadas recientemente, con el fin de conocer los \'ultimos enfoques presentados que fueron utilizados efectivamente para an\'alisis de sentimientos. Seleccionamos preferentemente trabajos con similitudes tales como el idioma abordado (espa\~nol o enfoques multiling\"ues), las fuentes de datos (mediadores de redes sociales) o las estrategias utilizadas (mediante l\'exicos o aprendizaje de m\'aquina).}

\paragraph{Moreno-Ortiz y P\'erez Hern\'andez (2013) presentan una propuesta basada en un l\'exico para categorizar textos cortos, al principio en cuatro categor\'ias de polaridad (positivos, negativos, neutros o sin polaridad) y luego agregando dos categor\'ias m\'as (muy positivos y muy negativos). El c\'alculo de polaridad est\'a centrado principalmente en dos valores num\'ericos denominados \textit{Global Sentiment Value} (GSV) y \textit{Affect Intensity} (AI); el primero, es un valor dentro de la escala de 0 a 10 asignado a sentimientos de acuerdo a una entrada de texto a partir del AI, el cual modula el GSV para reflejar el porcentaje de palabras con cierta carga de sentimientos. El AI no es un contador de palabras por polaridad, sino que de segmentos de texto que correspondan a unidades l\'exicas, definido como el porcentaje de segmentos que presentan determinada carga de polaridad, representando un paso intermedio para el ajuste de los l\'imites superior e inferior de las valencias relacionadas con el grado de sentimientos. Finalmente, concluyen que los valores de GSV se ven fuertemente afectados por la escasez de segmentos l\'exicos en los mensajes de Twitter; que la tendencia de la herramienta utilizada es la asignaci\'on de clasificaciones promedio, reflejada en la baja precisi\'on para las dos \'ultimas categor\'ias agregadas como ``extremos'' y adem\'as, que no es recomendable la diferenciaci\'on entre la categor\'ia de neutro con la de ausencia de polaridad.}

\paragraph{Vilares, Alonso y G\'omez-Rodr\'iguez (2013) presentan una propuesta basada en un l\'exico complementada con an\'alisis sint\'actico de dependencias, para tratar las construcciones ling\"u\'isticas e identificar los elementos implicados en las oraciones. El preprocesamiento, fundamental para el posterior an\'alisis sint\'actico, implica la unificaci\'on de expresiones compuestas que act\'uan como una sola unidad de significado, la normalizaci\'on de signos de puntuaci\'on y la segmentaci\'on del texto en oraciones, adem\'as de la separaci\'on de ellas en \textit{tokens} de palabras y signos de puntuaci\'on. El \'arbol de dependencias creado permite identificar relaciones binarias entre los elementos de una oraci\'on, en el cual cada v\'inculo constituye una funci\'on sint\'actica que relaciona dos t\'erminos. En cuanto al an\'alisis sem\'antico, la propuesta se basa en el diccionario de polaridad compuesto de adjetivos, sustantivos, verbos, adverbios e intensificadores propuesto por (Brooke, Tofiloski y Taboada, 2009), con la diferencia de que utilizan el \'arbol de dependencias para determinar cu\'al segmento de una oraci\'on se ve afectado por la modificaci\'on de los intensificadores, por la negaci\'on y las oraciones adversativas. En este trabajo, no se tratan los problemas de las palabras orientadas al dominio ni las figuras literarias tales como la iron\'ia o el sarcasmo. Concluyen que las t\'ecnicas de an\'alisis de dependencias resultan \'utiles para identificar de manera fiable el alcance de la negaci\'on en las oraciones y adem\'as proponen futuras adecuaciones para expresiones desiderativas as\'i como para el tratamiento de textos cortos.}

\paragraph{Bautin, Skiena y Vijayarenu (2008) presentan una propuesta multiling\"ue, mediante traducci\'on por m\'aquina con el fin de contrastar diferentes lenguajes de corpus paralelos. El an\'alisis fue hecho sobre escritos formales en nueve lenguajes, y adem\'as un corpus paralelo de cinco idiomas. Concluyen finalmente que la t\'ecnica de normalizaci\'on propuesta permite que la comparaci\'on de categorizaci\'on por polaridad en idiomas diferentes sea posible y que los errores de traducci\'on no son significativos, haciendo viables las comparaciones interculturales para an\'alisis de sentimientos.}

\paragraph{Una estrategia de co-entrenamiento es la propuesta de Wan (2009) para crear un l\'exico en Mandar\'in a partir de uno en Ingl\'es. Un conjunto de documentos de cada idioma, elaborados a trav\'es de traducci\'on por m\'aquina, son utilizados para evaluar el clasificador. Para estimar la polaridad de un documento en particular, deber\'ia ser clasificado correctamente tanto en Ingl\'es como en Mandar\'in. Los resultados demuestran que la propuesta presentada es muy efectiva para el tratamiento de diversos lenguajes.}

\paragraph{Boey y Moens (2008) presentan una estrategia de aprendizaje de m\'aquina que eval\'ua modelos mediante una arquitectura en cascada por capas, contando como fuente con un n\'umero limitado de entradas etiquetadas y en las cuales los textos no son escrituras formales. La propuesta consiste en tres capas de evaluaci\'on, cada una con diferente precisi\'on y velocidad en la computaci\'on de los resultados. Los idiomas tratados son el Ingl\'es, el Holand\'es y el Franc\'es. La clasificaci\'on en diferentes lenguajes es adem\'as tratada separadamente, de tal manera que puedan ser discutidas las diferencias entre los resultados obtenidos sobre cada uno de ellos. La conclusi\'on a la que arribaron es que el aprendizaje activo y continuo produce una notoria mejor\'ia sobre las muestras seleccionados aleatoriamente para el etiquetado, y adem\'as que el rendimiento obtenido fue mejor cuando aplicaron un filtro sobre las oraciones neutrales previa a la aplicaci\'on de los algoritmos de clasificaci\'on.}

\paragraph{} 

\section{Discusi\'on final del cap\'itulo}
\paragraph{En este cap\'itulo, presentamos los fundamentos te\'eoricos del an\'alisis de sentimientos, primeramente descripto de manera general como un proceso de descubrimiento de conocimiento, en el cual tras seleccionar, procesar y transformar los datos de entrada, buscamos extraer patrones para generar informaci\'on, que finalmente debe ser evaluada para cuantificar su utilidad. Luego, describimos las dos alternativas principales que existen para categorizar textos por polaridad; siendo uno de ellos basado en un l\'exico, es decir, vali\'endose de un diccionario o un corpus de entrada y teniendo en cuenta las reglas gramaticales del lenguaje de entrada; y por otro lado, la estrategia por aprendizaje de m\'aquina, que busca detectar patrones a trav\'es de un conjunto de entrenamiento generado previamente para permitir clasificar nuevas entradas dentro de un grupo de clases definidas.}
\paragraph{Describimos adem\'as algunas m\'etricas de evaluaci\'on que ser\'an utilizadas luego en  el problema propuesto, pues uno de los objetivos es comparar entre s\'i, el rendimiento obtenido tras la aplicaci\'on de las diferentes estrategias citadas. Sumarizamos finalmente, el estado del arte describiendo algunos trabajos con caracter\'isticas similares a las propuestas en este documento. En ellos, vemos que se utilizan los algoritmos ya presentados, que se tratan lenguajes diferentes en un mismo clasificador y que se da un tratamiento particular a los textos en formato corto e informal.}
\paragraph{En el siguiente cap\'itulo, describimos el problema a tratar, el modelado propuesto para resolverlo, en base a los fundamentos esbozados en este cap\'itulo y los objetivos de evaluaci\'on trazados.}
