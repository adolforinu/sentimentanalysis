\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Miner\'ia y an\'alisis computacional de sentimientos}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Mineria}{{2}{4}}
\@writefile{toc}{\contentsline {paragraph}{Las opiniones son fuertemente influyentes sobre el comportamiento de las personas en la mayor\'ia de sus actividades. Nuestras creencias, decisiones y percepci\'on de la realidad est\'an condicionadas por la visi\'on que perciben las dem\'as personas en nuestro entorno. El \'area de estudio denominada ``an\'alisis de sentimientos'', conocida tambi\'en como ``miner\'ia de opiniones'' se ocupa de conceptos tales como opini\'on, sentimiento, actitud y evaluaci\'on (Liu, 2012).}{4}}
\@writefile{toc}{\contentsline {paragraph}{En este cap\'itulo definimos el an\'alisis computacional como un Proceso de Descubrimiento de Conocimiento (KDD por sus siglas en ingl\'es, \textit  {Knowledge Discovery in Databases}) y como un \'area de estudio del Procesamiento de Lenguaje Natural (PLN). Luego, se presentan las estrategias m\'as utilizadas en el campo, adem\'as de una breve descripci\'on de los trabajos similares m\'as recientes que utilizan dichas estrategias para la clasificaci\'on de sentimientos.}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Proceso de Descubrimiento de Conocimiento}{4}}
\@writefile{toc}{\contentsline {paragraph}{Los datos son un conjunto discreto de hechos sobre ciertos eventos; los datos en s\'i no describen las condiciones de un evento, o posibles interpretaciones sobre el mismo, solamente sumarizan caracter\'isticas de dichos eventos. Su importancia radica en que sirven de materia prima en el proceso de generaci\'on de informaci\'on.}{4}}
\@writefile{toc}{\contentsline {paragraph}{Los datos se convierten en informaci\'on cuando el receptor de dichos datos da un sentido o interpretaci\'on a los mismos, entonces podemos definir a la informaci\'on como un conjunto de datos con sentido, relevancia y prop\'osito para el receptor de los datos.}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Etapas en el proceso de KDD}}{5}}
\newlabel{etapaskdd}{{2.1}{5}}
\@writefile{toc}{\contentsline {paragraph}{A partir de informaciones obtenidas, podemos definir KDD como el proceso no trivial de identificaci\'on de patrones v\'alidos, novedosos, potencialmente \'utiles y comprensibles en un conjunto de datos (Fayyad y otros, 1996). Este proceso puede ser aplicado al an\'alisis de sentimientos, puesto que buscamos identificar patrones en un lenguaje de entrada, que describan significativamente las opiniones del tal manera que podamos clasificarlas, por ejemplo, como ``positivas'' o ``negativas'' y presentarlas como informaci\'on generada.}{5}}
\@writefile{toc}{\contentsline {paragraph}{En el proceso de KDD podemos distinguir una serie de etapas, como se puede observar en la Figura \ref  {etapaskdd}, las cuales describimos a continuaci\'on: }{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Preprocesamiento de entradas}{7}}
\@writefile{toc}{\contentsline {paragraph}{Este paso se efect\'ua previamente al de la estrategia de categorizaci\'on seleccionada, con el objetivo de limitar y refinar los espacios de b\'usqueda. En esta etapa del proceso se define cu\'ales entradas son relevantes y la disposici\'on m\'as eficiente en la que pueden ser introducidas al proceso de clasificaci\'on. Algunas t\'ecnicas de preprocesamiento son las siguientes:}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Estrategias basadas en l\'exicos}{8}}
\@writefile{toc}{\contentsline {paragraph}{En cualquier lenguaje, existen palabras com\'unmente utilizadas para expresar opini\'on o ``sentimiento'' con una orientaci\'on determinada respecto a una entidad en particular. Dicha orientaci\'on puede ser positiva o negativa; por ejemplo: ``bueno'', ``genial'' y ``espectacular'' son entradas positivas; mientras que ``malo'', ``p\'esimo'' y ``horrible'' son entradas negativas. Estas palabras, denominadas \textit  {sentiment words} (SW, por sus siglas en ingl\'es) en conjunto conforman un l\'exico de sentimientos u opiniones. Para conformar dicho l\'exico, pueden ser tomados como fuentes distintos textos escritos, cuyos contenidos traten de evaluar o expresar opini\'on sobre alguna entidad, como por ejemplo cr\'iticas, libros, recetas, p\'aginas Web, entre otros.}{8}}
\@writefile{toc}{\contentsline {paragraph}{Las SW podemos clasificar en palabras descriptivas y comparativas. Las palabras descriptivas expresan calificaci\'on sobre una entidad, tales como las citadas en el p\'arrafo anterior; mientras que las palabras comparativas establecen confrontaci\'on entre dos entidades, generando opiniones superlativas. Por ejemplo, en la oraci\'on ``El producto A es mejor que el producto B'' no se establece calificaci\'on positiva ni negativa para alguno de los productos, sino que solamente en comparaci\'on al producto B, el A es mejor. Esto no implica que ``mejor'' sea exclusivamente una SW comparativa para cualquier oraci\'on, sino que cumple tal funci\'on en el contexto dado.}{9}}
\@writefile{toc}{\contentsline {paragraph}{En algunos l\'exicos, la orientaci\'on sem\'antica de las palabras es cuantificada generalmente por valores num\'ericos, que luego son introducidos en una funci\'on de puntuaci\'on, para determinar la polaridad de una opini\'on acerca de una entidad determinada. Dicha funci\'on var\'ia seg\'un el an\'alisis de distintos autores; as\'i como los criterios de cuantificaci\'on de las orientaciones sem\'anticas. En algunos trabajos, se limitan a asignar signos positivos y negativos (+1 y -1) a las palabras (Ding y otros, 2008); mientras que en otros, se emplea un intervalo m\'as amplio para obtener un mejor balance de la suma final de polaridades, como (Taboada y otros, 2011) que utilizan un intervalo de puntuaci\'on de -5 a +5. Estas puntuaciones, as\'i como las funciones definidas para el c\'alculo de polaridad, pueden influir en la precisi\'on de resultados logrados.}{9}}
\@writefile{toc}{\contentsline {paragraph}{En (Liu, 2012) se identifican tres tipos de estrategia para compilar SW que conformen un l\'exico: la generaci\'on manual, la generaci\'on basada en un diccionario y la generaci\'on basada en un corpus.}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}L\'exico generado manualmente}{9}}
\@writefile{toc}{\contentsline {paragraph}{Seguir esta estrategia implica un costo muy alto de trabajo y de tiempo, por tanto generalmente no es utilizada de manera exclusiva. Tiene su utilidad en combinaci\'on con estrategias automatizadas mediante tareas tales como una verificaci\'on final de palabras, puesto que con los m\'etodos automatizados se pueden generar errores.}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}L\'exico basado en un diccionario}{9}}
\@writefile{toc}{\contentsline {paragraph}{La construcci\'on de un diccionario implica un listado de sin\'onimos y ant\'onimos para cada palabra. Un m\'etodo sencillo de generaci\'on es utilizar como semillas algunas SW, a partir de las cuales se pueden encontrar las dem\'as palabras del diccionario a partir de los sin\'onimos y ant\'onimos de las semillas. A medida que dichos sin\'onimos son agregados como nuevas palabras semilla, el diccionario va creciendo sucesivamente. Algunos trabajos que se ocupan de la generaci\'on de un diccionario son (Hu y Liu, 2004) y (Kim y Hovy, 2004).}{9}}
\@writefile{toc}{\contentsline {paragraph}{La ventaja de utilizar un diccionario es que se puede encontrar f\'acil y r\'apidamente un gran n\'umero de SW con sus orientaciones sem\'anticas. A pesar de que la lista resultante puede incluir varios errores, es posible efectuar una verificaci\'on manual de limpieza para refinar el diccionario. Por otro lado, la principal desventaja es que la lista de palabras generadas en un diccionario son de prop\'osito muy general (no orientadas al dominio de aplicaci\'on) y dependientes del contexto. Esta dificultad puede tratada mediante la generaci\'on de un corpus.}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}L\'exico basado en un corpus}{10}}
\@writefile{toc}{\contentsline {paragraph}{Esta estrategia fue mayormente aplicada frente a dos escenarios:}{10}}
\@writefile{toc}{\contentsline {paragraph}{Construir un l\'exico de sentimientos para un dominio espec\'ifico puede no ser suficiente puesto que en el mismo dominio, una misma palabra puede ser positiva en un contexto, pero negativo en otro. Esta estrategia tambi\'en puede ser utilizada para construir un l\'exico de prop\'osito general en el caso que se encuentre disponible un corpus muy grande y diverso, pero para tal prop\'osito es m\'as efectiva la elaboraci\'on de un diccionario, puesto que el mismo ya est\'a compuesto por todas las palabras. Algunos trabajos que tratan la generaci\'on de un corpus son (Turney, 2002) y (Ding y otros, 2008). }{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Procesamiento de Lenguaje Natural}{10}}
\@writefile{toc}{\contentsline {paragraph}{Para extraer las opiniones o sentimientos (informaci\'on) a partir de un texto, el an\'alisis del mismo debe ser tratado como un problema de PLN. Como tal, debe considerar todos los aspectos de ella, como por ejemplo la desambiguaci\'on de palabras, las negaciones, intensificaciones, decrementaciones, entre otros.}{10}}
\@writefile{toc}{\contentsline {paragraph}{El problema espec\'ifico de extracci\'on de opiniones, es un problema de PLN restringido puesto que no es necesario entender completamente la sem\'antica de cada oraci\'on o documento, mas debe interpretar \'unicamente ciertos aspectos de ellos, como los sentimientos positivos o negativos y las entidades o t\'opicos a los que se refieren. De todas maneras, existen tambi\'en otros problemas a\'un no resueltos de PLN que agregan ciertas dificultades al proceso de an\'alisis. A continuaci\'on, describimos algunos t\'opicos que representan tanto aspectos comunes como dificultades que son tratadas en los problemas de PLN.}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Estrategias basadas en aprendizaje de m\'aquina}{12}}
\@writefile{toc}{\contentsline {paragraph}{La estrategia basada en aprendizaje de m\'aquina, tambi\'en referida como estad\'istica o clasificadora de textos, consiste en entrenar un clasificador para categorizar elementos de entrada dentro de una clase perteneciente a un conjunto definido de clases; por ejemplo, de sentimientos positivos, negativos o neutrales. El objetivo es generalizar comportamientos a trav\'es de informaci\'on previamente recolectada, denominada conjunto de entrenamiento, en forma de ejemplos, que luego puedan ser utilizados para evaluar un texto en funci\'on a sus similaridades.}{12}}
\@writefile{toc}{\contentsline {paragraph}{En t\'erminos generales un conjunto de entrenamiento, llamado en ingl\'es \textit  {training set}, es un conjunto de datos que se utiliza para realizar pruebas iniciales sobre un modelo conceptual esperando conseguir una descripci\'on comprensible de dicho modelo y a partir del mismo, la generaci\'on de conocimiento.}{12}}
\@writefile{toc}{\contentsline {paragraph}{Podemos identificar dos tipos de aprendizaje en esta estrategia: supervisado y no supervisado.}{13}}
\@writefile{toc}{\contentsline {paragraph}{En un m\'etodo de aprendizaje supervisado, se produce una funci\'on de correspondencia entre las entradas y salidas deseadas del sistema; como por ejemplo clasificar las palabras seg\'un su categor\'ia l\'exica (verbos, sustantivos, adjetivos, etc), categor\'ia funcional (determinantes, cuantificadores, pronombres, etc) o su polaridad (positivas, negativas, neutras, etc), por lo que se necesita una base de conocimiento previamente elaborada, compuesta por ejemplos de etiquetados anteriores.}{13}}
\@writefile{toc}{\contentsline {paragraph}{Los m\'etodos de aprendizaje no supervisado se llevan a cabo sobre conjuntos de ejemplos conformados \'unicamente por entradas al sistema; sin etiquetado de categor\'ias, a diferencia de los m\'etodos supervisados; por lo que el sistema debe tener capacidad de reconocimiento de patrones para etiquetar nuevas entradas. }{13}}
\@writefile{toc}{\contentsline {paragraph}{Algunos clasificadores de aprendizaje de m\'aquina son \textit  {Na\"ive Bayes} (NB), \textit  {Maximum Entropy} (ME) y \textit  {Support Vector Machines} (SVM). En las siguientes subseccciones, definimos cada uno de ellos, utilizando el siguiente conjunto de variables:}{13}}
\@writefile{toc}{\contentsline {paragraph}{El objetivo es determinar a qu\'e clase $c$ pertenece cada documento $d$.}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Na\"ive Bayes}{13}}
\@writefile{toc}{\contentsline {paragraph}{El algoritmo basado en el teorema de Bayes, aplicado al an\'alisis de textos, consiste en clasificar cada palabra de acuerdo a la probabilidad de que pertenezca a un determinado grupo. Tales agrupaciones pueden estar determinadas por categor\'ias gramaticales o por polaridad. La clasificaci\'on por etiquetas gramaticales (\textit  {POS tagging}) permite, por ejemplo, establecer la probabilidad de que la palabra siguiente a un sustantivo sea un verbo; con el objetivo de determinar qu\'e influencia tiene una palabra en la polaridad de un texto. En este contexto, un adjetivo es m\'as descriptivo que un sustantivo para la inferencia del sentimiento transmitido en un texto. La asociaci\'on por polaridad, en cambio relaciona las palabras que componen una oraci\'on con el sentimiento que ellas en conjunto transmiten. Es decir, las palabras utilizadas en una oraci\'on considerada positiva son, con mayor probabilidad, palabras con asociaci\'on positiva para cualquier otra oraci\'on.}{14}}
\@writefile{toc}{\contentsline {paragraph}{El clasificador \textit  {Na\"ive Bayes} deriva del teorema de la probabilidad condicional de dos eventos aleatorios $A$ y $B$ enunciado por Thomas Bayes, donde ``la probabilidad del evento $A$ dado $B$'' est\'a expresado por la siguiente f\'ormula:}{14}}
\@writefile{toc}{\contentsline {paragraph}{Llevando dicho teorema al problema de la clasificaci\'on de textos y utilizando el conjunto de variables antes definido, el primer paso consiste en estimar la probabilidad $P(c)$ de cada clase $c$, dividiendo el n\'umero de palabras presentes en los documentos etiquetados en $c$ entre la cantidad total de palabras en el corpus $C$. Luego, la distribuci\'on de probabilidad $P(w \, | \, c)$ para todas las palabras por cada clase $c$ est\'a dada por la divisi\'on de la cantidad de ocurrencias de $w$ en los documentos etiquetados en $c$ entre la cantidad de palabras en $c$.}{14}}
\@writefile{toc}{\contentsline {paragraph}{De esta manera, podremos asignar un valor num\'erico a un documento para cada una de las clases, para luego asociarlo a una de ellas. Dicho valor est\'a dado por:}{14}}
\@writefile{toc}{\contentsline {paragraph}{Luego, la estimaci\'on del modelo ser\'a de aquella clase cuyo valor de $score$ haya resultado mayor que el valor obtenido para las dem\'as clases.}{14}}
\@writefile{toc}{\contentsline {paragraph}{La dificultad en la aplicaci\'on de este algoritmo es que est\'a cimentado en la hip\'otesis de que las variables evaluadas son independientes entre s\'i (visto en la multiplicaci\'on de los valores de $P(w_{i} \, | \, c)$ en la definici\'on de $score$); y como la gram\'atica es por el contrario, dependiente del contexto, muchas entradas son clasificadas err\'oneamente, originando los fen\'omenos conocidos como ``falsos positivos'' o ``falsos negativos'' si tratamos la polaridad. Sin embargo, los resultados pueden ser a\'un muy positivos con la determinaci\'on de un buen conjunto de entrenamiento.}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Maximum Entropy}{15}}
\@writefile{toc}{\contentsline {paragraph}{El clasificador por entrop\'ia m\'axima trata de generar informaci\'on reduciendo el sesgo al m\'inimo posible. El principio fundamental del algoritmo es que son preferidas las distribuciones uniformes que satisfacen adem\'as todas las restricciones del problema (Nigam y otros, 1999). Dichas restricciones que caracterizan al modelo, son derivadas de los datos etiquetados del conjunto de entrenamiento.}{15}}
\@writefile{toc}{\contentsline {paragraph}{El algoritmo trata de identificar las caracter\'isticas que definen una clase, definiendo un modelo que englobe las reglas que puedan ser inferidas del conjunto de entrenamiento. Luego, estima un valor esperado para cada una de las clases definidas, de manera a tratarlos como restricciones en el modelo de distribuci\'on (Lee y Renganathan, 2011).}{15}}
\@writefile{toc}{\contentsline {paragraph}{A diferencia del algoritmo de \textit  {Na\"ive Bayes}, no asume la independencia entre variables. En cambio, el modelo busca mediante las restricciones mencionadas, maximizar la adherencia entre atributos en relaci\'on a alguna clase, de tal manera que una nueva entrada ser\'a categorizada dentro una clase cuanto menos caracter\'isticas extr\'insecas a su definici\'on contenga.}{15}}
\@writefile{toc}{\contentsline {paragraph}{Nigam y otros (1999) definen la probabilidad $P(c \, | \, d)$ de cada clase de la siguiente manera:}{15}}
\@writefile{toc}{\contentsline {paragraph}{Con la siguiente definici\'on de par\'ametros:}{16}}
\@writefile{toc}{\contentsline {paragraph}{La b\'usqueda de $\lambda _{i}$ se realiza por medio de algoritmos de b\'usqueda iterativa definidos seg\'un el modelo, como por ejemplo el m\'etodo de \textit  {Hill Climbing} o el de temple simulado.}{16}}
\@writefile{toc}{\contentsline {paragraph}{Las dificultades que pueden presentarse con el m\'etodo de entrop\'ia m\'axima son la facilidad con la que se presentan casos de \textit  {overfitting} (sobreentrenamiento del algoritmo con los datos de entrada dados, que produce p\'erdida de generalizaci\'on para datos nuevos) y el tiempo que pueda emplearse en la determinaci\'on de los pesos puesto que las iteraciones para calcularlos pueden llegar a ser infinitas.}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Support Vector Machines}{16}}
\@writefile{toc}{\contentsline {paragraph}{La t\'ecnica de clasificaci\'on por \textit  {Support Vector Machines} efect\'ua la separaci\'on de puntos un espacio $N$-dimensional utilizando un hiperplano $(N-1)$-dimensional, a diferencia de las t\'ecnicas de Bayes y entrop\'ia m\'axima, que utilizan medidas probabil\'isticas para clasificar los puntos. Dado un conjunto de entrenamiento, el clasificador por SVM busca encontrar un hiperplano con el mayor margen posible, de manera que cada punto del conjunto de entrenamiento sea clasificado correctamente y que el hiperplano se encuentre a la m\'axima distancia posible de sus puntos m\'as cercanos. La clasificaci\'on de las instancias de entrenamiento consiste en determinar a qu\'e lado del hiperplano caen ellas. En la pr\'actica, es posible que no se encuentre un hiperplano que separe los grupos perfectamente, por lo que los puntos pueden hallarse dentro del margen o del lado incorrecto del hiperplano.}{16}}
\@writefile{toc}{\contentsline {paragraph}{Si representamos el hiperplano buscado por el vector $\mathaccent "017E\relax {w}$, la b\'usqueda corresponde a un problema de optimizaci\'on con restricciones, siendo $c_{j} \, \in \, \{1,-1\}$ (positiva y negativa) la clase correcta del texto $d_{j}$, la soluci\'on puede ser escrita como:}{17}}
\@writefile{toc}{\contentsline {paragraph}{donde las $\alpha _{j}$ son obtenidas por resoluci\'on de un problema de optimizaci\'on. Los vectores $\mathaccent "017E\relax {d_{j}}$, tal que $\alpha _{j}$ es mayor que cero, son llamados vectores de soporte, dado que son los \'unicos que contribuyen al hiperplano $\mathaccent "017E\relax {w}$.}{17}}
\@writefile{toc}{\contentsline {paragraph}{Ha sido demostrado varias veces que este m\'etodo es altamente efectivo para la categorizaci\'on de textos, obteniendo generalmente mejores resultados que la t\'ecnica de Bayes (Joachims, 1998; Pang y otros, 2002; Kennedy e Inkpen, 2006).}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}M\'etricas de evaluaci\'on}{17}}
\@writefile{toc}{\contentsline {paragraph}{La evaluaci\'on de la clasificaci\'on se efect\'ua primariamente con el objetivo de comparar el desempe\~no de distintos sistemas o m\'etodos entre s\'i. La relevancia y utilidad de los resultados obtenidos prevalecen sobre los tiempos y espacios de respuesta cuando evaluamos una estrategia de an\'alisis de textos. No existe un \'unico criterio que permita determinar que un m\'etodo es mejor que otro; por ello, existen diversas m\'etricas para medir la efectividad de la informaci\'on obtenida del an\'alisis.}{17}}
\@writefile{toc}{\contentsline {paragraph}{Las m\'etricas que presentamos en esta secci\'on est\'an basadas en la matriz de confusi\'on o de clasificaci\'on. Dicha matriz contrasta la estimaci\'on del modelo clasificador para un elemento dado, con la clase real asociada a dicho elemento.}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Matriz de confusi\'on o de clasificaci\'on}}{18}}
\newlabel{matrizconfusion}{{2.1}{18}}
\@writefile{toc}{\contentsline {paragraph}{Dado un conjunto de datos $E$, donde cada elemento $e$ puede ser representado como un vector $< e_1, e_2, \dots  , e_n >$ de $n$ atributos, y un conjunto de clases $C$; cada vector $e \in E$ tiene una clase $c \in C$ asociada. La clasificaci\'on consiste en asignar una clase $c \in C$ para cada elemento $e \in E$, y el objetivo es cuantificar la efectividad de dichas asignaciones. Para dicho efecto, las filas de la matriz de confusi\'on representan las clases reales a la que pertenecen cada uno de los elementos y las columnas representan a la predicci\'on del modelo clasificador, como se observa en el Cuadro \ref  {matrizconfusion}.}{18}}
\@writefile{toc}{\contentsline {paragraph}{Referenciando los sub\'indices de filas y columnas como $[i,j]$, una entrada Verdadera representa un acierto, es decir si el clasificador ha determinado que un elemento $e$ pertenece a la $Clase_j$ y dicho elemento efectivamente est\'a asociado a la $Clase_j$; mientras que una entrada Falsa representa un error de clasificaci\'on, es decir que el elemento $e$ no pertenec\'ia efectivamente a la $Clase_j$.}{18}}
\@writefile{toc}{\contentsline {paragraph}{Definimos a continuaci\'on algunas m\'etricas de evaluaci\'on, en cuyas definiciones referenciamos a los aciertos y errores con el sub\'indice de la fila $i$ a la que pertenecen en la matriz de confusi\'on, como Verdadero de la $Clase_i$ o Falso de la $Clase_i$ :}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Precisi\'on}{18}}
\@writefile{toc}{\contentsline {paragraph}{La precisi\'on respecto a la $Clase_i$ indica el n\'umero de predicciones correctas sobre el total de predicciones de dicha clase. Es decir, indica la probabilidad de que un elemento $e$ pertenezca realmente a la $Clase_i$ dado que fue identificado como tal por el clasificador. Est\'a dado por la proporci\'on de verdaderos de la $Clase_i$ en relaci\'on a los totales identificados como de dicha clase: }{18}}
\@writefile{toc}{\contentsline {paragraph}{ $$ Precisi\mathaccent "7013\relax {o}n = {V Clase_i \over V Clase_i + F Clase_i} $$ }{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Recall}{18}}
\@writefile{toc}{\contentsline {paragraph}{El \textit  {recall} respecto a la $Clase_i$ indica el n\'umero de predicciones acertadas como $Clase_i$ sobre el total de elementos que realmente pertenecen a dicha clase. Es la probabilidad de que un elemento $e$ que pertenece realmente a la $Clase_i$ sea clasificado como tal. Est\'a dado por la raz\'on entre los verdaderos de la $Clase_i$, sobre los elementos reales de la $Clase_i$, en la matriz de confusi\'on dados por la suma de los verdaderos de la $Clase_i$ m\'as los falsos de las dem\'as clases.}{19}}
\@writefile{toc}{\contentsline {paragraph}{ $$ Recall = { V Clase_i \over V Clase_i + F Clase_j } \hskip 1em\relax donde \hskip 1em\relax j \in \delimiter "4266308 1,2,\dots  ,n \delimiter "5267309 \hskip 1em\relax con \hskip 1em\relax j \not =i $$ }{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Medida-F}{19}}
\@writefile{toc}{\contentsline {paragraph}{Relaciona las medidas de precisi\'on y \textit  {recall} mediante una media con el mismo peso para ambas. Es conocida tambi\'en como $F_1$ por la uniformidad de los pesos.}{19}}
\@writefile{toc}{\contentsline {paragraph}{ $$ Medida-F = {2 \, \times Precisi\mathaccent "7013\relax {o}n \, \times \, Recall \over Precisi\mathaccent "7013\relax {o}n \, + \, Recall}$$ }{19}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Propuestas similares}{19}}
\@writefile{toc}{\contentsline {paragraph}{En esta secci\'on, describimos algunas propuestas publicadas recientemente, con el fin de conocer los \'ultimos enfoques presentados que fueron utilizados efectivamente para an\'alisis de sentimientos. Seleccionamos preferentemente trabajos con similitudes tales como el idioma abordado (espa\~nol o enfoques multiling\"ues), las fuentes de datos (mediadores de redes sociales) o las estrategias utilizadas (mediante l\'exicos o aprendizaje de m\'aquina).}{19}}
\@writefile{toc}{\contentsline {paragraph}{Moreno-Ortiz y P\'erez Hern\'andez (2013) presentan una propuesta basada en un l\'exico para categorizar textos cortos, al principio en cuatro categor\'ias de polaridad (positivos, negativos, neutros o sin polaridad) y luego agregando dos categor\'ias m\'as (muy positivos y muy negativos). El c\'alculo de polaridad est\'a centrado principalmente en dos valores num\'ericos denominados \textit  {Global Sentiment Value} (GSV) y \textit  {Affect Intensity} (AI); el primero, es un valor dentro de la escala de 0 a 10 asignado a sentimientos de acuerdo a una entrada de texto a partir del AI, el cual modula el GSV para reflejar el porcentaje de palabras con cierta carga de sentimientos. El AI no es un contador de palabras por polaridad, sino que de segmentos de texto que correspondan a unidades l\'exicas, definido como el porcentaje de segmentos que presentan determinada carga de polaridad, representando un paso intermedio para el ajuste de los l\'imites superior e inferior de las valencias relacionadas con el grado de sentimientos. Finalmente, concluyen que los valores de GSV se ven fuertemente afectados por la escasez de segmentos l\'exicos en los mensajes de Twitter; que la tendencia de la herramienta utilizada es la asignaci\'on de clasificaciones promedio, reflejada en la baja precisi\'on para las dos \'ultimas categor\'ias agregadas como ``extremos'' y adem\'as, que no es recomendable la diferenciaci\'on entre la categor\'ia de neutro con la de ausencia de polaridad.}{20}}
\@writefile{toc}{\contentsline {paragraph}{Vilares, Alonso y G\'omez-Rodr\'iguez (2013) presentan una propuesta basada en un l\'exico complementada con an\'alisis sint\'actico de dependencias, para tratar las construcciones ling\"u\'isticas e identificar los elementos implicados en las oraciones. El preprocesamiento, fundamental para el posterior an\'alisis sint\'actico, implica la unificaci\'on de expresiones compuestas que act\'uan como una sola unidad de significado, la normalizaci\'on de signos de puntuaci\'on y la segmentaci\'on del texto en oraciones, adem\'as de la separaci\'on de ellas en \textit  {tokens} de palabras y signos de puntuaci\'on. El \'arbol de dependencias creado permite identificar relaciones binarias entre los elementos de una oraci\'on, en el cual cada v\'inculo constituye una funci\'on sint\'actica que relaciona dos t\'erminos. En cuanto al an\'alisis sem\'antico, la propuesta se basa en el diccionario de polaridad compuesto de adjetivos, sustantivos, verbos, adverbios e intensificadores propuesto por (Brooke, Tofiloski y Taboada, 2009), con la diferencia de que utilizan el \'arbol de dependencias para determinar cu\'al segmento de una oraci\'on se ve afectado por la modificaci\'on de los intensificadores, por la negaci\'on y las oraciones adversativas. En este trabajo, no se tratan los problemas de las palabras orientadas al dominio ni las figuras literarias tales como la iron\'ia o el sarcasmo. Concluyen que las t\'ecnicas de an\'alisis de dependencias resultan \'utiles para identificar de manera fiable el alcance de la negaci\'on en las oraciones y adem\'as proponen futuras adecuaciones para expresiones desiderativas as\'i como para el tratamiento de textos cortos.}{20}}
\@writefile{toc}{\contentsline {paragraph}{Bautin, Skiena y Vijayarenu (2008) presentan una propuesta multiling\"ue, mediante traducci\'on por m\'aquina con el fin de contrastar diferentes lenguajes de corpus paralelos. El an\'alisis fue hecho sobre escritos formales en nueve lenguajes, y adem\'as un corpus paralelo de cinco idiomas. Concluyen finalmente que la t\'ecnica de normalizaci\'on propuesta permite que la comparaci\'on de categorizaci\'on por polaridad en idiomas diferentes sea posible y que los errores de traducci\'on no son significativos, haciendo viables las comparaciones interculturales para an\'alisis de sentimientos.}{21}}
\@writefile{toc}{\contentsline {paragraph}{Una estrategia de co-entrenamiento es la propuesta de Wan (2009) para crear un l\'exico en Mandar\'in a partir de uno en Ingl\'es. Un conjunto de documentos de cada idioma, elaborados a trav\'es de traducci\'on por m\'aquina, son utilizados para evaluar el clasificador. Para estimar la polaridad de un documento en particular, deber\'ia ser clasificado correctamente tanto en Ingl\'es como en Mandar\'in. Los resultados demuestran que la propuesta presentada es muy efectiva para el tratamiento de diversos lenguajes.}{21}}
\@writefile{toc}{\contentsline {paragraph}{Boey y Moens (2008) presentan una estrategia de aprendizaje de m\'aquina que eval\'ua modelos mediante una arquitectura en cascada por capas, contando como fuente con un n\'umero limitado de entradas etiquetadas y en las cuales los textos no son escrituras formales. La propuesta consiste en tres capas de evaluaci\'on, cada una con diferente precisi\'on y velocidad en la computaci\'on de los resultados. Los idiomas tratados son el Ingl\'es, el Holand\'es y el Franc\'es. La clasificaci\'on en diferentes lenguajes es adem\'as tratada separadamente, de tal manera que puedan ser discutidas las diferencias entre los resultados obtenidos sobre cada uno de ellos. La conclusi\'on a la que arribaron es que el aprendizaje activo y continuo produce una notoria mejor\'ia sobre las muestras seleccionados aleatoriamente para el etiquetado, y adem\'as que el rendimiento obtenido fue mejor cuando aplicaron un filtro sobre las oraciones neutrales previa a la aplicaci\'on de los algoritmos de clasificaci\'on.}{21}}
\@writefile{toc}{\contentsline {paragraph}{}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Discusi\'on final del cap\'itulo}{22}}
\@writefile{toc}{\contentsline {paragraph}{En este cap\'itulo, presentamos los fundamentos te\'eoricos del an\'alisis de sentimientos, primeramente descripto de manera general como un proceso de descubrimiento de conocimiento, en el cual tras seleccionar, procesar y transformar los datos de entrada, buscamos extraer patrones para generar informaci\'on, que finalmente debe ser evaluada para cuantificar su utilidad. Luego, describimos las dos alternativas principales que existen para categorizar textos por polaridad; siendo uno de ellos basado en un l\'exico, es decir, vali\'endose de un diccionario o un corpus de entrada y teniendo en cuenta las reglas gramaticales del lenguaje de entrada; y por otro lado, la estrategia por aprendizaje de m\'aquina, que busca detectar patrones a trav\'es de un conjunto de entrenamiento generado previamente para permitir clasificar nuevas entradas dentro de un grupo de clases definidas.}{22}}
\@writefile{toc}{\contentsline {paragraph}{Describimos adem\'as algunas m\'etricas de evaluaci\'on que ser\'an utilizadas luego en el problema propuesto, pues uno de los objetivos es comparar entre s\'i, el rendimiento obtenido tras la aplicaci\'on de las diferentes estrategias citadas. Sumarizamos finalmente, el estado del arte describiendo algunos trabajos con caracter\'isticas similares a las propuestas en este documento. En ellos, vemos que se utilizan los algoritmos ya presentados, que se tratan lenguajes diferentes en un mismo clasificador y que se da un tratamiento particular a los textos en formato corto e informal.}{22}}
\@writefile{toc}{\contentsline {paragraph}{En el siguiente cap\'itulo, describimos el problema a tratar, el modelado propuesto para resolverlo, en base a los fundamentos esbozados en este cap\'itulo y los objetivos de evaluaci\'on trazados.}{22}}
\@setckpt{mineria}{
\setcounter{page}{23}
\setcounter{equation}{0}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{7}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{1}
\setcounter{table}{1}
}
